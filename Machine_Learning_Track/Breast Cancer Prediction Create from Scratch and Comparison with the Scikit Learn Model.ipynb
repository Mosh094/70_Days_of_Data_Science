{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import numpy as np\n",
    "import warnings\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Euclidean Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbors (data, predict, k=3):\n",
    "    if len(data) >= k:\n",
    "        warning.warn('k is set to a value less than the total number of voting groups!')\n",
    "    distances = []\n",
    "    for group in data:\n",
    "        for features in data[group]:\n",
    "            #ecludiean distance can be gotten using either of the following:\n",
    "            #euclidean_distance = sqrt( (features[0]-predict[0])**2 + (features[1]-predict[1])**2)\n",
    "            #euclidean_distance = np.sqrt( np.sum((np.array(features) - np.array(predict))**2))\n",
    "            euclidean_distance = np.linalg.norm(np.array(features) - np.array(predict)) #this is the faster of the 3\n",
    "            distances.append([euclidean_distance, group])\n",
    "    vote = [i[1] for i in sorted(distances)[:k]]\n",
    "    #print(Counter(vote).most_common(1)) # comment this out to print only accuracy and not individual predictions\n",
    "    vote_result = Counter(vote).most_common(1)[0][0]\n",
    "    confidence = Counter(vote).most_common(1)[0][1]/k #creating confidence\n",
    "    #print(vote_result, confidence) #uncomment to print vote and confidence\n",
    "    return vote_result, confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('breast-cancer-wisconsin.data') #Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clump_thickness</th>\n",
       "      <th>Unif_cell_size</th>\n",
       "      <th>Unif_cell_shape</th>\n",
       "      <th>marg_adhesion</th>\n",
       "      <th>single_epith_cell</th>\n",
       "      <th>Bare_Nuclei</th>\n",
       "      <th>Bland_Chromatin</th>\n",
       "      <th>Normal_Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  clump_thickness  Unif_cell_size  Unif_cell_shape  marg_adhesion  \\\n",
       "0  1000025                5               1                1              1   \n",
       "1  1002945                5               4                4              5   \n",
       "2  1015425                3               1                1              1   \n",
       "3  1016277                6               8                8              1   \n",
       "4  1017023                4               1                1              3   \n",
       "\n",
       "   single_epith_cell Bare_Nuclei  Bland_Chromatin  Normal_Nucleoli  Mitoses  \\\n",
       "0                  2           1                3                1        1   \n",
       "1                  7          10                3                2        1   \n",
       "2                  2           2                3                1        1   \n",
       "3                  3           4                3                7        1   \n",
       "4                  2           1                3                1        1   \n",
       "\n",
       "   Class  \n",
       "0      2  \n",
       "1      2  \n",
       "2      2  \n",
       "3      2  \n",
       "4      2  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head() #Display first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace Missing Data and Drop Irrelivant Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('?', -99999, inplace=True) #replace missing data with -99999 this is a very large outlier to avoid conflit\n",
    "df.drop(['id'], 1, inplace=True) #drop the id column as it doesnt contribute to our prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cast all variables to float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0],\n",
       " [5.0, 4.0, 4.0, 5.0, 7.0, 10.0, 3.0, 2.0, 1.0, 2.0],\n",
       " [3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 2.0],\n",
       " [6.0, 8.0, 8.0, 1.0, 3.0, 4.0, 3.0, 7.0, 1.0, 2.0],\n",
       " [4.0, 1.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0],\n",
       " [8.0, 10.0, 10.0, 8.0, 7.0, 10.0, 9.0, 7.0, 1.0, 4.0],\n",
       " [1.0, 1.0, 1.0, 1.0, 2.0, 10.0, 3.0, 1.0, 1.0, 2.0],\n",
       " [2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0],\n",
       " [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 5.0, 2.0],\n",
       " [4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0]]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df.astype(float).values.tolist() #to convert all values to float\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffle Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.0, 1.0, 1.0, 3.0, 8.0, 1.0, 5.0, 8.0, 1.0, 2.0], [4.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0], [8.0, 10.0, 10.0, 1.0, 3.0, 6.0, 3.0, 9.0, 1.0, 4.0], [8.0, 4.0, 10.0, 5.0, 4.0, 4.0, 7.0, 10.0, 1.0, 4.0], [2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0], [5.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0], [6.0, 5.0, 5.0, 8.0, 4.0, 10.0, 3.0, 4.0, 1.0, 4.0], [8.0, 4.0, 4.0, 1.0, 6.0, 10.0, 2.0, 5.0, 2.0, 4.0], [6.0, 8.0, 8.0, 1.0, 3.0, 4.0, 3.0, 7.0, 1.0, 2.0], [5.0, 4.0, 5.0, 1.0, 8.0, 1.0, 3.0, 6.0, 1.0, 2.0]]\n"
     ]
    }
   ],
   "source": [
    "#shuffle data\n",
    "random.shuffle(data)\n",
    "print(data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data to Training and Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train-test\n",
    "test_size = 0.2\n",
    "train_set = {2:[], 4:[]}\n",
    "test_set = {2:[], 4:[]}\n",
    "train_data = data[:-int(test_size*len(data))] #split train data = from beginning to the last 20% of the data\n",
    "test_data = data[-int(test_size*len(data)):] #split test data = last 20% of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# populate the train set and test set dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_data:\n",
    "    train_set[i[-1]].append(i[:-1]) #exclude the class column, which is what we are predicting\n",
    "    \n",
    "for i in test_data:\n",
    "    test_set[i[-1]].append(i[:-1]) #exclude the class column, which is what we are predicting\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass the information into k_nearest_neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.8\n",
      "0.6\n",
      "0.6\n",
      "1.0\n",
      "0.6\n",
      "Accuracy: 0.9568345323741008\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for group in test_set:\n",
    "    for data in test_set[group]:\n",
    "        vote, confidence = k_nearest_neighbors (train_set, data, k=5) #increasing k increases the accuracy at a point then drops as k becomes too high. so adding to k might not increase the model \n",
    "        if group == vote:\n",
    "            correct += 1\n",
    "        else:\n",
    "            print(confidence) # gives confidence of votes that are incorrect\n",
    "        total += 1\n",
    "print ('Accuracy:', correct/total) # i.e number of correct out of total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
